{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ecae33-2caa-47b2-8d8c-45f303133e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c7f724-4dcd-4aa5-8981-a9e8bf36a55f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Twitter API key and token\n",
    "consumer_key = \"T9nRwVAvf3ajTmOM7dSSMOab1\"\n",
    "consumer_key_secret = \"KD0HAo7dYE5YscFVoTzllZNXAJHPGmuYaCdCZtSUyW2g9Xqt8K\"\n",
    "access_token = '1429992676665958446-z6eHXZyYTEdwm9SVRbPzVIJZd682Tt'\n",
    "access_token_secret = 'Pfc5zkImVN64u8Dg3DdaYRh9FN8g1nkG3t3ZUmWXTx4GF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5209d762-c232-4e0c-be43-f86caf79ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61497f6d-fa2c-451a-bdf8-514951ad5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract only lang=en to tsv_file_en\n",
    "tsv_file = open(r\"C:\\Users\\alice\\Downloads\\full_dataset_clean.tsv\\full_dataset_clean.tsv\", 'r+')\n",
    "tsv_file_en = open(r\"C:\\Users\\alice\\Downloads\\full_dataset_clean.tsv\\full_dataset_clean_en.tsv\", 'a+')\n",
    "df = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "counter = 0\n",
    "for line in df:\n",
    "    if counter % 10000000 == 0:\n",
    "        print(counter, '/316800308')   #keep track of the download \n",
    "    if line[3] == 'en':\n",
    "        tsv_file_en.write('\\t'.join(line)+'\\n')\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64f339-e6ed-49d8-baf4-11677ee33eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the english file and add an english_sentiment file\n",
    "tsv_file_en = open(r\"C:\\Users\\alice\\Downloads\\full_dataset_clean.tsv\\full_dataset_clean_en.tsv\", 'r+') \n",
    "tsv_file_en_sentiment = open(r\"C:\\Users\\alice\\Downloads\\full_dataset_clean.tsv\\full_dataset_clean_en_sentiment.tsv\", 'a+')\n",
    "df = csv.reader(tsv_file_en, delimiter=\"\\t\")\n",
    "\n",
    "#twitter API\n",
    "consumer_key = \"T9nRwVAvf3ajTmOM7dSSMOab1\"\n",
    "consumer_key_secret = \"KD0HAo7dYE5YscFVoTzllZNXAJHPGmuYaCdCZtSUyW2g9Xqt8K\"\n",
    "access_token = '1429992676665958446-7uISC1suhMVojkRARiUoM7nDjGz7YK'\n",
    "access_token_secret = 'QMgO85iDuIBnO8e20HKCApvSPqF3IMI7ICJrazDupOk4W'\n",
    "\n",
    "#accessing tweet, code from https://morioh.com/p/eabbdfdd1f0b\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "#read tweeter id and calculate sentiment and subjectivity \n",
    "counter = 0\n",
    "for line in df:\n",
    "    if counter % 10000000 == 0:\n",
    "        print(counter, '/150000000')\n",
    "    try:\n",
    "        tweetFetched = api.get_status(line[0])   #sentiment and subjectivity code from https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis\n",
    "        testimonial = TextBlob(tweetFetched.text)\n",
    "        line += [str(testimonial.sentiment[0]), str(testimonial.sentiment[1])]\n",
    "    except:\n",
    "        line += ['nan', 'nan'] #since some twitter_id cannot read, used \"nan\" to represent those tweets\n",
    "        \n",
    "    tsv_file_en_sentiment.write('\\t'.join(line)+'\\n')\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
